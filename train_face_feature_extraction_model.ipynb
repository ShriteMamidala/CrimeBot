{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torchvision import transforms, models\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING']='1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_dir = r\"C:\\Users\\shrit\\Desktop\\Ml_Projects\\Ml_Projects\\Data\\fair_face\\train\\images\"\n",
    "val_img_dir = r\"C:\\Users\\shrit\\Desktop\\Ml_Projects\\Ml_Projects\\Data\\fair_face\\val\\images\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>service_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.jpg</td>\n",
       "      <td>50-59</td>\n",
       "      <td>Male</td>\n",
       "      <td>East Asian</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.jpg</td>\n",
       "      <td>30-39</td>\n",
       "      <td>Female</td>\n",
       "      <td>Indian</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.jpg</td>\n",
       "      <td>3-9</td>\n",
       "      <td>Female</td>\n",
       "      <td>Black</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.jpg</td>\n",
       "      <td>20-29</td>\n",
       "      <td>Female</td>\n",
       "      <td>Indian</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.jpg</td>\n",
       "      <td>20-29</td>\n",
       "      <td>Female</td>\n",
       "      <td>Indian</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85897</th>\n",
       "      <td>86739.jpg</td>\n",
       "      <td>20-29</td>\n",
       "      <td>Male</td>\n",
       "      <td>Middle Eastern</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85898</th>\n",
       "      <td>86740.jpg</td>\n",
       "      <td>20-29</td>\n",
       "      <td>Male</td>\n",
       "      <td>Indian</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85899</th>\n",
       "      <td>86741.jpg</td>\n",
       "      <td>10-19</td>\n",
       "      <td>Male</td>\n",
       "      <td>Indian</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85900</th>\n",
       "      <td>86743.jpg</td>\n",
       "      <td>10-19</td>\n",
       "      <td>Female</td>\n",
       "      <td>Black</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85901</th>\n",
       "      <td>86744.jpg</td>\n",
       "      <td>40-49</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85902 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            file    age  gender            race  service_test\n",
       "0          1.jpg  50-59    Male      East Asian          True\n",
       "1          2.jpg  30-39  Female          Indian         False\n",
       "2          3.jpg    3-9  Female           Black         False\n",
       "3          4.jpg  20-29  Female          Indian          True\n",
       "4          5.jpg  20-29  Female          Indian          True\n",
       "...          ...    ...     ...             ...           ...\n",
       "85897  86739.jpg  20-29    Male  Middle Eastern          True\n",
       "85898  86740.jpg  20-29    Male          Indian          True\n",
       "85899  86741.jpg  10-19    Male          Indian          True\n",
       "85900  86743.jpg  10-19  Female           Black          True\n",
       "85901  86744.jpg  40-49    Male           White         False\n",
       "\n",
       "[85902 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\shrit\\Desktop\\Ml_Projects\\Ml_Projects\\Data\\fair_face\\train\\fairface_label_train_cleaned.csv')\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shrit\\AppData\\Local\\Temp\\ipykernel_42912\\913567728.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['race'] = df['race'].replace({'Southeast Asian': 'East Asian'})\n"
     ]
    }
   ],
   "source": [
    "df = df[~df['age'].isin(['0-2', '3-9', '60-69'])]\n",
    "df['race'] = df['race'].replace({'Southeast Asian': 'East Asian'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shrit\\AppData\\Local\\Temp\\ipykernel_42912\\3960336617.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['age'] = df['age'].map(age_mapping).astype(int)\n",
      "C:\\Users\\shrit\\AppData\\Local\\Temp\\ipykernel_42912\\3960336617.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['race'] = df['race'].map(race_mapping)\n",
      "C:\\Users\\shrit\\AppData\\Local\\Temp\\ipykernel_42912\\3960336617.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['gender'] = df['gender'].map(gender_mapping)\n"
     ]
    }
   ],
   "source": [
    "age_mapping = {\n",
    "    '10-19': 0,\n",
    "    '20-29': 1,\n",
    "    '30-39': 2,\n",
    "    '40-49': 3,\n",
    "    '50-59': 4,\n",
    "}\n",
    "\n",
    "df['age'] = df['age'].map(age_mapping).astype(int)\n",
    "\n",
    "race_mapping = {\n",
    "    'East Asian': 0,\n",
    "    'Indian': 1,\n",
    "    'Black': 2,\n",
    "    'White': 3,\n",
    "    'Middle Eastern': 4,\n",
    "    'Latino_Hispanic': 5\n",
    "}\n",
    "\n",
    "#numerical labels\n",
    "df['race'] = df['race'].map(race_mapping)\n",
    "\n",
    "\n",
    "gender_mapping = {\n",
    "    'Male': 0,\n",
    "    'Female': 1\n",
    "}\n",
    "\n",
    "#  binary \n",
    "df['gender'] = df['gender'].map(gender_mapping)\n",
    "\n",
    "train_df = df.drop(columns=['service_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    file  age  gender  race\n",
       "0  1.jpg    4       0     0\n",
       "1  2.jpg    2       1     1\n",
       "3  4.jpg    1       1     1\n",
       "4  5.jpg    1       1     1\n",
       "5  6.jpg    1       0     3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(r'C:\\Users\\shrit\\Desktop\\Ml_Projects\\Ml_Projects\\Data\\fair_face\\train\\fairface_label_train_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>service_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.jpg</td>\n",
       "      <td>3-9</td>\n",
       "      <td>Male</td>\n",
       "      <td>East Asian</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.jpg</td>\n",
       "      <td>50-59</td>\n",
       "      <td>Female</td>\n",
       "      <td>East Asian</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.jpg</td>\n",
       "      <td>30-39</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.jpg</td>\n",
       "      <td>20-29</td>\n",
       "      <td>Female</td>\n",
       "      <td>Latino_Hispanic</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.jpg</td>\n",
       "      <td>20-29</td>\n",
       "      <td>Male</td>\n",
       "      <td>Southeast Asian</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10831</th>\n",
       "      <td>10950.jpg</td>\n",
       "      <td>30-39</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10832</th>\n",
       "      <td>10951.jpg</td>\n",
       "      <td>50-59</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10833</th>\n",
       "      <td>10952.jpg</td>\n",
       "      <td>60-69</td>\n",
       "      <td>Male</td>\n",
       "      <td>Latino_Hispanic</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10834</th>\n",
       "      <td>10953.jpg</td>\n",
       "      <td>20-29</td>\n",
       "      <td>Female</td>\n",
       "      <td>East Asian</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10835</th>\n",
       "      <td>10954.jpg</td>\n",
       "      <td>40-49</td>\n",
       "      <td>Male</td>\n",
       "      <td>Latino_Hispanic</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10836 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            file    age  gender             race  service_test\n",
       "0          1.jpg    3-9    Male       East Asian         False\n",
       "1          2.jpg  50-59  Female       East Asian          True\n",
       "2          3.jpg  30-39    Male            White          True\n",
       "3          4.jpg  20-29  Female  Latino_Hispanic          True\n",
       "4          5.jpg  20-29    Male  Southeast Asian         False\n",
       "...          ...    ...     ...              ...           ...\n",
       "10831  10950.jpg  30-39    Male            White          True\n",
       "10832  10951.jpg  50-59    Male            White         False\n",
       "10833  10952.jpg  60-69    Male  Latino_Hispanic         False\n",
       "10834  10953.jpg  20-29  Female       East Asian         False\n",
       "10835  10954.jpg  40-49    Male  Latino_Hispanic          True\n",
       "\n",
       "[10836 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\shrit\\Desktop\\Ml_Projects\\Ml_Projects\\Data\\fair_face\\val\\fairface_label_val_cleaned.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shrit\\AppData\\Local\\Temp\\ipykernel_42912\\913567728.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['race'] = df['race'].replace({'Southeast Asian': 'East Asian'})\n"
     ]
    }
   ],
   "source": [
    "df = df[~df['age'].isin(['0-2', '3-9', '60-69'])]\n",
    "df['race'] = df['race'].replace({'Southeast Asian': 'East Asian'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shrit\\AppData\\Local\\Temp\\ipykernel_42912\\2122856892.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['age'] = df['age'].map(age_mapping).astype(int)\n",
      "C:\\Users\\shrit\\AppData\\Local\\Temp\\ipykernel_42912\\2122856892.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['race'] = df['race'].map(race_mapping)\n",
      "C:\\Users\\shrit\\AppData\\Local\\Temp\\ipykernel_42912\\2122856892.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['gender'] = df['gender'].map(gender_mapping)\n"
     ]
    }
   ],
   "source": [
    "age_mapping = {\n",
    "    '10-19': 0,\n",
    "    '20-29': 1,\n",
    "    '30-39': 2,\n",
    "    '40-49': 3,\n",
    "    '50-59': 4,\n",
    "}\n",
    "\n",
    "\n",
    "df['age'] = df['age'].map(age_mapping).astype(int)\n",
    "\n",
    "race_mapping = {\n",
    "    'East Asian': 0,\n",
    "    'Indian': 1,\n",
    "    'Black': 2,\n",
    "    'White': 3,\n",
    "    'Middle Eastern': 4,\n",
    "    'Latino_Hispanic': 5\n",
    "}\n",
    "\n",
    "df['race'] = df['race'].map(race_mapping)\n",
    "\n",
    "\n",
    "gender_mapping = {\n",
    "    'Male': 0,\n",
    "    'Female': 1\n",
    "}\n",
    "\n",
    "df['gender'] = df['gender'].map(gender_mapping)\n",
    "\n",
    "val_df = df.drop(columns=['service_test'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    file  age  gender  race\n",
       "1  2.jpg    4       1     0\n",
       "2  3.jpg    2       0     3\n",
       "3  4.jpg    1       1     5\n",
       "4  5.jpg    1       0     0\n",
       "5  6.jpg    2       0     5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.to_csv(r'C:\\Users\\shrit\\Desktop\\Ml_Projects\\Ml_Projects\\Data\\fair_face\\val\\fairface_label_val_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['gender'] = train_df['gender'].astype(float)\n",
    "val_df['gender'] = val_df['gender'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_path = r\"C:\\Users\\shrit\\Desktop\\Ml_Projects\\Ml_Projects\\Data\\fair_face\\train\\images\"\n",
    "val_image_path = r\"C:\\Users\\shrit\\Desktop\\Ml_Projects\\Ml_Projects\\Data\\fair_face\\val\\images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskModel(nn.Module):\n",
    "    def __init__(self, device=\"cuda\"):\n",
    "        super(MultiTaskModel, self).__init__()\n",
    "        #  pretrained EfficientNet as transfer learning\n",
    "        self.backbone = models.efficientnet_b0(pretrained=True)  # Use B0 variant bc its fast\n",
    "        self.backbone.classifier = nn.Identity()  # remove classification layer\n",
    "        \n",
    "        # add custom heads for multi-task \n",
    "        self.age_head = nn.Sequential(\n",
    "    nn.Dropout(0.2),  # dropout\n",
    "    nn.Linear(1280, 5)\n",
    "    )\n",
    "        self.gender_head = nn.Sequential(\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(1280, 1)\n",
    "    )\n",
    "        self.race_head = nn.Sequential(\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(1280, 6)\n",
    "    )\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)  # features from the EfficientNet \n",
    "        age_out = self.age_head(features)\n",
    "        gender_out = self.gender_head(features)\n",
    "        race_out = self.race_head(features)\n",
    "        return age_out, gender_out, race_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FairFaceDataset(Dataset): #transforming the dataset to make it work\n",
    "    def __init__(self, dataframe, root_dir, transform=None):\n",
    "        self.data = dataframe\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir, self.data.iloc[idx, 0])\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        \n",
    "        # Extract labels\n",
    "        age = self.data.iloc[idx, 1]\n",
    "        gender = self.data.iloc[idx, 2]\n",
    "        race = self.data.iloc[idx, 3]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, torch.tensor(age, dtype=torch.long), torch.tensor(gender, dtype=torch.float), torch.tensor(race, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop((224, 224)),  #  EfficientNet input size\n",
    "    transforms.RandomHorizontalFlip(), # augmentations\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # ImageNet normalization\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FairFaceDataset(dataframe=train_df, root_dir=train_image_path, transform=train_transform)\n",
    "val_dataset = FairFaceDataset(dataframe=val_df, root_dir=val_image_path, transform=val_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True,pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False,pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shrit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\shrit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MultiTaskModel(device=device).to(device) #useing GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_age = nn.CrossEntropyLoss()\n",
    "criterion_gender = nn.BCEWithLogitsLoss()  # Use raw \n",
    "criterion_race = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique age labels: [4 2 1 3 0]\n",
      "Unique race labels: [0 1 3 4 5 2]\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique age labels:\", train_df['age'].unique())\n",
    "print(\"Unique race labels:\", train_df['race'].unique()) # testing age labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiTaskModel(\n",
       "  (backbone): EfficientNet(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): SiLU(inplace=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (2): Conv2dNormActivation(\n",
       "              (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.0125, mode=row)\n",
       "        )\n",
       "        (1): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
       "              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.037500000000000006, mode=row)\n",
       "        )\n",
       "        (1): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "              (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.05, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
       "              (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.0625, mode=row)\n",
       "        )\n",
       "        (1): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.07500000000000001, mode=row)\n",
       "        )\n",
       "        (2): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.08750000000000001, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
       "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
       "        )\n",
       "        (1): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.1125, mode=row)\n",
       "        )\n",
       "        (2): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.125, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (6): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
       "              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.1375, mode=row)\n",
       "        )\n",
       "        (1): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.15000000000000002, mode=row)\n",
       "        )\n",
       "        (2): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.1625, mode=row)\n",
       "        )\n",
       "        (3): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.17500000000000002, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (7): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.1875, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (8): Conv2dNormActivation(\n",
       "        (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): SiLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "    (classifier): Identity()\n",
       "  )\n",
       "  (age_head): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=False)\n",
       "    (1): Linear(in_features=1280, out_features=5, bias=True)\n",
       "  )\n",
       "  (gender_head): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=False)\n",
       "    (1): Linear(in_features=1280, out_features=1, bias=True)\n",
       "  )\n",
       "  (race_head): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=False)\n",
       "    (1): Linear(in_features=1280, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam([\n",
    "    {'params': model.backbone.parameters(), 'lr': 1e-6},  # Smaller LR for pre-trained backbone\n",
    "    {'params': model.age_head.parameters(), 'lr': 1e-4},  # Larger LR for new heads\n",
    "    {'params': model.gender_head.parameters(), 'lr': 1e-4},\n",
    "    {'params': model.race_head.parameters(), 'lr': 1e-4},\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha, beta, gamma = 1.5, 1.0, 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, dataloader, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct_age, correct_gender, correct_race = 0, 0, 0\n",
    "    total_samples = 0\n",
    "\n",
    "    scaler = torch.amp.GradScaler()\n",
    "    progress_bar = tqdm(dataloader, desc=\"Training\", unit=\"batch\")\n",
    "\n",
    "    for images, age_labels, gender_labels, race_labels in progress_bar:\n",
    "        images, age_labels, gender_labels, race_labels = (\n",
    "            images.to(device),\n",
    "            age_labels.to(device),\n",
    "            gender_labels.to(device),\n",
    "            race_labels.to(device),\n",
    "        )\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Use autocast for mixed precision operations\n",
    "        with torch.amp.autocast(device_type='cuda'):\n",
    "            age_out, gender_out, race_out = model(images)\n",
    "\n",
    "            # Compute losses\n",
    "            loss_age = criterion_age(age_out, age_labels)\n",
    "            loss_gender = criterion_gender(gender_out.squeeze(), gender_labels)\n",
    "            loss_race = criterion_race(race_out, race_labels)\n",
    "\n",
    "            # Combine losses\n",
    "            loss = alpha * loss_age + beta * loss_gender + gamma * loss_race\n",
    "\n",
    "        # Backward pass using scaler\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # Update total loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Compute predictions and accuracy\n",
    "        age_preds = torch.argmax(age_out, dim=1)\n",
    "        gender_preds = torch.round(torch.sigmoid(gender_out.squeeze()))\n",
    "        race_preds = torch.argmax(race_out, dim=1)\n",
    "\n",
    "        correct_age += (age_preds == age_labels).sum().item()\n",
    "        correct_gender += (gender_preds == gender_labels).sum().item()\n",
    "        correct_race += (race_preds == race_labels).sum().item()\n",
    "\n",
    "        total_samples += age_labels.size(0)\n",
    "\n",
    "        progress_bar.set_postfix({\n",
    "            \"Loss\": loss.item(),\n",
    "            \"Age Acc\": f\"{(correct_age / total_samples) * 100:.2f}%\",\n",
    "            \"Gender Acc\": f\"{(correct_gender / total_samples) * 100:.2f}%\",\n",
    "            \"Race Acc\": f\"{(correct_race / total_samples) * 100:.2f}%\"\n",
    "        })\n",
    "\n",
    "    # Overall accuracy\n",
    "    age_acc = correct_age / total_samples\n",
    "    gender_acc = correct_gender / total_samples\n",
    "    race_acc = correct_race / total_samples\n",
    "\n",
    "    return total_loss / len(dataloader), age_acc, gender_acc, race_acc\n",
    "\n",
    "def validate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct_age, correct_gender, correct_race = 0, 0, 0\n",
    "    total_samples = 0\n",
    "\n",
    "    progress_bar = tqdm(dataloader, desc=\"Validating\", unit=\"batch\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        with torch.amp.autocast(device_type='cuda'):\n",
    "            for images, age_labels, gender_labels, race_labels in progress_bar:\n",
    "                images, age_labels, gender_labels, race_labels = (\n",
    "                    images.to(device),\n",
    "                    age_labels.to(device),\n",
    "                    gender_labels.to(device),\n",
    "                    race_labels.to(device),\n",
    "                )\n",
    "                age_out, gender_out, race_out = model(images)\n",
    "\n",
    "                # Compute losses\n",
    "                loss_age = criterion_age(age_out, age_labels)\n",
    "                loss_gender = criterion_gender(gender_out.squeeze(), gender_labels)\n",
    "                loss_race = criterion_race(race_out, race_labels)\n",
    "\n",
    "                loss = loss_age + loss_gender + loss_race\n",
    "                total_loss += loss.item()\n",
    "\n",
    "                # Compute predictions and accuracy\n",
    "                age_preds = torch.argmax(age_out, dim=1)\n",
    "                gender_preds = torch.round(torch.sigmoid(gender_out.squeeze()))\n",
    "                race_preds = torch.argmax(race_out, dim=1)\n",
    "\n",
    "                correct_age += (age_preds == age_labels).sum().item()\n",
    "                correct_gender += (gender_preds == gender_labels).sum().item()\n",
    "                correct_race += (race_preds == race_labels).sum().item()\n",
    "\n",
    "                total_samples += age_labels.size(0)\n",
    "\n",
    "                progress_bar.set_postfix({\n",
    "                    \"Loss\": loss.item(),\n",
    "                    \"Age Acc\": f\"{(correct_age / total_samples) * 100:.2f}%\",\n",
    "                    \"Gender Acc\": f\"{(correct_gender / total_samples) * 100:.2f}%\",\n",
    "                    \"Race Acc\": f\"{(correct_race / total_samples) * 100:.2f}%\"\n",
    "                })\n",
    "\n",
    "    # Overall accuracy\n",
    "    age_acc = correct_age / total_samples\n",
    "    gender_acc = correct_gender / total_samples\n",
    "    race_acc = correct_race / total_samples\n",
    "\n",
    "    return total_loss / len(dataloader), age_acc, gender_acc, race_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 8/1109 [00:02<06:01,  3.05batch/s, Loss=5.83, Age Acc=20.31%, Gender Acc=51.95%, Race Acc=16.80%]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# Unpack training and validation results\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m     train_loss, train_age_acc, train_gender_acc, train_race_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     val_loss, val_age_acc, val_gender_acc, val_race_acc \u001b[38;5;241m=\u001b[39m validate(model, val_loader, device)\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m# Print epoch performance\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[26], line 33\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[1;34m(model, dataloader, optimizer, device)\u001b[0m\n\u001b[0;32m     30\u001b[0m     loss \u001b[38;5;241m=\u001b[39m alpha \u001b[38;5;241m*\u001b[39m loss_age \u001b[38;5;241m+\u001b[39m beta \u001b[38;5;241m*\u001b[39m loss_gender \u001b[38;5;241m+\u001b[39m gamma \u001b[38;5;241m*\u001b[39m loss_race\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Backward pass using scaler\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m scaler\u001b[38;5;241m.\u001b[39mstep(optimizer)\n\u001b[0;32m     35\u001b[0m scaler\u001b[38;5;241m.\u001b[39mupdate()\n",
      "File \u001b[1;32mc:\\Users\\shrit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    580\u001b[0m     )\n\u001b[1;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\shrit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\shrit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_model_path = \"best_face_age_gender_race_extraction_state_dict2.pth\"\n",
    "\n",
    "# Variable to track the best validation loss\n",
    "best_val_loss = float(\"inf\")\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    # Unpack training and validation results\n",
    "    train_loss, train_age_acc, train_gender_acc, train_race_acc = train_one_epoch(model, train_loader, optimizer, device)\n",
    "    val_loss, val_age_acc, val_gender_acc, val_race_acc = validate(model, val_loader, device)\n",
    "\n",
    "    # Print epoch performance\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Age Acc: {train_age_acc * 100:.2f}%, Gender Acc: {train_gender_acc * 100:.2f}%, Race Acc: {train_race_acc * 100:.2f}%\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}, Age Acc: {val_age_acc * 100:.2f}%, Gender Acc: {val_gender_acc * 100:.2f}%, Race Acc: {val_race_acc * 100:.2f}%\")\n",
    "\n",
    "    # Check if this is the best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), best_model_path)  # Save only state_dict\n",
    "        print(f\"Best model state_dict saved at epoch {epoch+1} with validation loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m results \u001b[38;5;241m=\u001b[39m []  \u001b[38;5;66;03m# List to store predictions and true labels\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_face_age_gender_race_extraction_full_model_dict.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "results = []  # List to store predictions and true labels\n",
    "model = torch.load(\"best_face_age_gender_race_extraction_full_model_dict2.pth\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, age_labels, gender_labels, race_labels in val_loader:  # or train_loader\n",
    "        images, age_labels, gender_labels, race_labels = (\n",
    "            images.to(device),\n",
    "            age_labels.to(device),\n",
    "            gender_labels.to(device),\n",
    "            race_labels.to(device),\n",
    "        )\n",
    "        \n",
    "        # Forward pass to get predictions\n",
    "        age_out, gender_out, race_out = model(images)\n",
    "\n",
    "        # Convert outputs to predictions\n",
    "        age_preds = torch.argmax(age_out, dim=1).cpu().numpy()\n",
    "        gender_preds = torch.round(torch.sigmoid(gender_out.squeeze())).cpu().numpy()\n",
    "        race_preds = torch.argmax(race_out, dim=1).cpu().numpy()\n",
    "\n",
    "        # Append results for each sample\n",
    "        for i in range(len(age_labels)):\n",
    "            results.append({\n",
    "                \"true_age\": age_labels[i].item(),\n",
    "                \"predicted_age\": age_preds[i],\n",
    "                \"true_gender\": gender_labels[i].item(),\n",
    "                \"predicted_gender\": gender_preds[i],\n",
    "                \"true_race\": race_labels[i].item(),\n",
    "                \"predicted_race\": race_preds[i],\n",
    "                \"age_confidence\": torch.softmax(age_out[i], dim=0).cpu().numpy(),\n",
    "                \"race_confidence\": torch.softmax(race_out[i], dim=0).cpu().numpy(),\n",
    "                \"gender_confidence\": torch.sigmoid(gender_out[i].squeeze()).cpu().item(),\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age Misclassified: 4689\n",
      "Gender Misclassified: 1227\n",
      "Race Misclassified: 3849\n"
     ]
    }
   ],
   "source": [
    "age_misclassified = [r for r in results if r[\"true_age\"] != r[\"predicted_age\"]]\n",
    "gender_misclassified = [r for r in results if r[\"true_gender\"] != r[\"predicted_gender\"]]\n",
    "race_misclassified = [r for r in results if r[\"true_race\"] != r[\"predicted_race\"]]\n",
    "\n",
    "print(\"Age Misclassified:\", len(age_misclassified))\n",
    "print(\"Gender Misclassified:\", len(gender_misclassified))\n",
    "print(\"Race Misclassified:\", len(race_misclassified))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age Misclassification by Class: Counter({2: 1610, 3: 960, 1: 940, 0: 755, 4: 424})\n",
      "Gender Misclassification by Class: Counter({1.0: 823, 0.0: 404})\n",
      "Race Misclassification by Class: Counter({5: 1034, 4: 714, 1: 640, 3: 604, 0: 510, 2: 347})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "age_errors = Counter([r[\"true_age\"] for r in age_misclassified])\n",
    "gender_errors = Counter([r[\"true_gender\"] for r in gender_misclassified])\n",
    "race_errors = Counter([r[\"true_race\"] for r in race_misclassified])\n",
    "\n",
    "print(\"Age Misclassification by Class:\", age_errors)\n",
    "print(\"Gender Misclassification by Class:\", gender_errors)\n",
    "print(\"Race Misclassification by Class:\", race_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Race: 3, Predicted Race: 4, Confidence: [0.13106075 0.03898117 0.00345048 0.31210607 0.3698356  0.14456597]\n",
      "True Race: 5, Predicted Race: 0, Confidence: [0.58087504 0.02934828 0.00495047 0.11416876 0.08435402 0.18630344]\n",
      "True Race: 5, Predicted Race: 4, Confidence: [0.07642388 0.06654444 0.01266471 0.2466833  0.41997445 0.17770919]\n",
      "True Race: 0, Predicted Race: 3, Confidence: [0.01512535 0.01880851 0.01108239 0.6046333  0.14544171 0.20490879]\n",
      "True Race: 5, Predicted Race: 3, Confidence: [0.0574134  0.0388911  0.01510215 0.58865404 0.05463748 0.2453018 ]\n",
      "True Race: 0, Predicted Race: 3, Confidence: [0.25892773 0.01099635 0.0202651  0.40851545 0.08500932 0.21628611]\n",
      "True Race: 3, Predicted Race: 2, Confidence: [0.08347745 0.27981693 0.34190553 0.08170161 0.05467979 0.1584187 ]\n",
      "True Race: 3, Predicted Race: 4, Confidence: [0.03970648 0.01477044 0.00052059 0.33934268 0.3843736  0.22128631]\n",
      "True Race: 4, Predicted Race: 2, Confidence: [0.05819422 0.03573163 0.26837817 0.16592196 0.2148345  0.25693956]\n",
      "True Race: 0, Predicted Race: 3, Confidence: [0.3102715  0.04013771 0.00989155 0.37751314 0.134543   0.12764302]\n"
     ]
    }
   ],
   "source": [
    "# Print examples of misclassified samples for race\n",
    "for r in race_misclassified[:10]:  # Limit to 5 examples\n",
    "    print(f\"True Race: {r['true_race']}, Predicted Race: {r['predicted_race']}, Confidence: {r['race_confidence']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "# Load the image\n",
    "image_path = \"C:\\\\Users\\\\shrit\\\\Desktop\\\\Ml_Projects\\\\Ml_Projects\\\\Data\\\\celeba\\\\img_align_celeba\\\\000001.jpg\" # Replace with your image file path\n",
    "image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "# Define preprocessing pipeline\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalization for feature model\n",
    "])\n",
    "\n",
    "# Preprocess the image\n",
    "image_tensor = preprocess(image)\n",
    "image_tensor = image_tensor.unsqueeze(0)  # Add batch dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shrit\\AppData\\Local\\Temp\\ipykernel_41464\\3722254749.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(r\"C:\\Users\\shrit\\Desktop\\Ml_Projects\\Ml_Projects\\Notebooks\\best_face_age_gender_race_extraction_full_model.pth\")  # Replace with your model path\n"
     ]
    }
   ],
   "source": [
    "# Load your pretrained face feature extraction model\n",
    "model = torch.load(r\"C:\\Users\\shrit\\Desktop\\Ml_Projects\\Ml_Projects\\Notebooks\\best_face_age_gender_race_extraction_full_model.pth\")  # Replace with your model path\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "import torch\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Move the model to the same device\n",
    "model = model.to(device)\n",
    "\n",
    "# Move the input tensor to the same device\n",
    "image_tensor = image_tensor.to(device)\n",
    "\n",
    "# Run the model\n",
    "with torch.no_grad():\n",
    "    output = model(image_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Values:\n",
      "(tensor([[-1.2899,  1.1020,  0.1450, -1.1026, -2.5615]], device='cuda:0'), tensor([[6.7359]], device='cuda:0'), tensor([[-0.1154, -1.0456, -2.5352,  0.4176, -0.2297,  0.4673]],\n",
      "       device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "print(f\"Output Values:\\n{output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Age Group: 20-29\n",
      "Predicted Gender: Female (Probability: 1.00)\n",
      "Predicted Race: Latino_Hispanic\n",
      "Race Probabilities: [0.17035566 0.0672012  0.0151507  0.2902764  0.15194598 0.30507004]\n"
     ]
    }
   ],
   "source": [
    "age_group_logits = output[0]\n",
    "predicted_age_group = torch.argmax(age_group_logits, dim=1).item()\n",
    "\n",
    "# Example age mapping\n",
    "age_mapping = {0: \"10-19\", 1: \"20-29\", 2: \"30-39\", 3: \"40-49\", 4: \"50-59\"}\n",
    "age_group_label = age_mapping[predicted_age_group]\n",
    "print(f\"Predicted Age Group: {age_group_label}\")\n",
    "\n",
    "\n",
    "\n",
    "gender_logits = output[1]\n",
    "gender_prob = torch.sigmoid(gender_logits).item()  # Probability of being \"Female\"\n",
    "\n",
    "# Example gender mapping\n",
    "gender_label = \"Female\" if gender_prob > 0.5 else \"Male\"\n",
    "print(f\"Predicted Gender: {gender_label} (Probability: {gender_prob:.2f})\")\n",
    "\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "race_logits = output[2]\n",
    "race_probs = F.softmax(race_logits, dim=1).squeeze(0).cpu().numpy()\n",
    "\n",
    "# Example race mapping\n",
    "race_mapping = {\n",
    "    0: \"East Asian\", 1: \"Indian\", 2: \"Black\", \n",
    "    3: \"White\", 4: \"Middle Eastern\", 5: \"Latino_Hispanic\"\n",
    "}\n",
    "\n",
    "predicted_race_index = torch.argmax(race_logits, dim=1).item()\n",
    "race_label = race_mapping[predicted_race_index]\n",
    "\n",
    "print(f\"Predicted Race: {race_label}\")\n",
    "print(f\"Race Probabilities: {race_probs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
